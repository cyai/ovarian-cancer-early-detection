{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. Data shape: (200100, 34)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Ovarian_patient_data.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Data loaded successfully. Data shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "Before any data manipulation, it is important to understand the data structure, types, and potential issues like missing values or duplicates.  \n",
    "This step helps in making informed preprocessing decisions, as described in Chen et al. (2019) :contentReference[oaicite:1]{index=1}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Dataset Information =====\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200100 entries, 0 to 200099\n",
      "Data columns (total 34 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   Timestamp               200100 non-null  object \n",
      " 1   Age                     200100 non-null  float64\n",
      " 2   BMI                     200100 non-null  float64\n",
      " 3   Comorbidity             200100 non-null  int64  \n",
      " 4   Symptom                 200100 non-null  int64  \n",
      " 5   CA125                   200100 non-null  float64\n",
      " 6   CancerStage             200100 non-null  int64  \n",
      " 7   Histopathology          200100 non-null  object \n",
      " 8   PreviousTreatment       200100 non-null  int64  \n",
      " 9   MenstrualHistory        200100 non-null  object \n",
      " 10  Ethnicity               200100 non-null  object \n",
      " 11  Smoking                 200100 non-null  int64  \n",
      " 12  Alcohol                 200100 non-null  int64  \n",
      " 13  Residence               200100 non-null  object \n",
      " 14  SocioeconomicStatus     200100 non-null  object \n",
      " 15  BRCA_Mutation           200100 non-null  int64  \n",
      " 16  GeneExpression          200100 non-null  float64\n",
      " 17  SNP_Status              200100 non-null  int64  \n",
      " 18  DNAMethylation          200100 non-null  float64\n",
      " 19  miRNA                   200100 non-null  float64\n",
      " 20  TumorSize               200100 non-null  float64\n",
      " 21  TumorLocation           200100 non-null  object \n",
      " 22  EnhancementPattern      200100 non-null  float64\n",
      " 23  RadiomicTexture         200100 non-null  float64\n",
      " 24  RadiomicIntensity       200100 non-null  float64\n",
      " 25  RadiomicShape           200100 non-null  float64\n",
      " 26  DopplerVelocity         200100 non-null  float64\n",
      " 27  Parity                  200100 non-null  int64  \n",
      " 28  OralContraceptives      200100 non-null  int64  \n",
      " 29  HormoneTherapy          200100 non-null  int64  \n",
      " 30  MenarcheAge             200100 non-null  float64\n",
      " 31  MenopauseAge            200100 non-null  float64\n",
      " 32  RiskLabel               200100 non-null  int64  \n",
      " 33  ProgressionProbability  200100 non-null  float64\n",
      "dtypes: float64(15), int64(12), object(7)\n",
      "memory usage: 51.9+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"===== Dataset Information =====\")\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Summary Statistics =====\n",
      "                  Timestamp            Age            BMI    Comorbidity  \\\n",
      "count                200100  200100.000000  200100.000000  200100.000000   \n",
      "unique               200100            NaN            NaN            NaN   \n",
      "top     2019-01-01 00:00:00            NaN            NaN            NaN   \n",
      "freq                      1            NaN            NaN            NaN   \n",
      "mean                    NaN      59.901575      28.003226       0.300000   \n",
      "std                     NaN      14.668235       4.980700       0.458259   \n",
      "min                     NaN      18.000000      15.000000       0.000000   \n",
      "25%                     NaN      49.891372      24.616558       0.000000   \n",
      "50%                     NaN      60.025998      27.998428       0.000000   \n",
      "75%                     NaN      70.141600      31.361152       1.000000   \n",
      "max                     NaN      90.000000      49.096832       1.000000   \n",
      "\n",
      "              Symptom          CA125    CancerStage Histopathology  \\\n",
      "count   200100.000000  200100.000000  200100.000000         200100   \n",
      "unique            NaN            NaN            NaN              3   \n",
      "top               NaN            NaN            NaN         serous   \n",
      "freq              NaN            NaN            NaN         140444   \n",
      "mean         0.402384      34.874555       0.996067            NaN   \n",
      "std          0.490380      34.411115       1.223703            NaN   \n",
      "min          0.000000       0.000018       0.000000            NaN   \n",
      "25%          0.000000      10.057735       0.000000            NaN   \n",
      "50%          0.000000      24.162441       0.000000            NaN   \n",
      "75%          1.000000      48.421526       2.000000            NaN   \n",
      "max          1.000000     200.000000       4.000000            NaN   \n",
      "\n",
      "        PreviousTreatment MenstrualHistory  ... RadiomicIntensity  \\\n",
      "count       200100.000000           200100  ...     200100.000000   \n",
      "unique                NaN                2  ...               NaN   \n",
      "top                   NaN          regular  ...               NaN   \n",
      "freq                  NaN           140157  ...               NaN   \n",
      "mean             0.199530              NaN  ...         50.030013   \n",
      "std              0.399648              NaN  ...          9.993355   \n",
      "min              0.000000              NaN  ...          6.215829   \n",
      "25%              0.000000              NaN  ...         43.288079   \n",
      "50%              0.000000              NaN  ...         50.004486   \n",
      "75%              0.000000              NaN  ...         56.784981   \n",
      "max              1.000000              NaN  ...         99.203153   \n",
      "\n",
      "        RadiomicShape  DopplerVelocity         Parity OralContraceptives  \\\n",
      "count   200100.000000    200100.000000  200100.000000      200100.000000   \n",
      "unique            NaN              NaN            NaN                NaN   \n",
      "top               NaN              NaN            NaN                NaN   \n",
      "freq              NaN              NaN            NaN                NaN   \n",
      "mean         0.999722         2.496380       0.653193           0.199940   \n",
      "std          0.275003         1.443022       0.911912           0.399956   \n",
      "min          0.500000         0.000007       0.000000           0.000000   \n",
      "25%          0.796569         1.243463       0.000000           0.000000   \n",
      "50%          1.000032         2.500433       0.000000           0.000000   \n",
      "75%          1.202314         3.743309       1.000000           0.000000   \n",
      "max          1.500000         4.999994       3.000000           1.000000   \n",
      "\n",
      "        HormoneTherapy    MenarcheAge   MenopauseAge      RiskLabel  \\\n",
      "count    200100.000000  200100.000000  200100.000000  200100.000000   \n",
      "unique             NaN            NaN            NaN            NaN   \n",
      "top                NaN            NaN            NaN            NaN   \n",
      "freq               NaN            NaN            NaN            NaN   \n",
      "mean          0.148931      13.014028      50.006837       0.650440   \n",
      "std           0.356021       1.468198       4.783299       0.909397   \n",
      "min           0.000000      10.000000      40.000000       0.000000   \n",
      "25%           0.000000      11.988691      46.674184       0.000000   \n",
      "50%           0.000000      12.999088      50.006139       0.000000   \n",
      "75%           0.000000      14.013925      53.357075       1.000000   \n",
      "max           1.000000      18.000000      60.000000       3.000000   \n",
      "\n",
      "        ProgressionProbability  \n",
      "count            200100.000000  \n",
      "unique                     NaN  \n",
      "top                        NaN  \n",
      "freq                       NaN  \n",
      "mean                  0.285436  \n",
      "std                   0.160168  \n",
      "min                   0.000647  \n",
      "25%                   0.160298  \n",
      "50%                   0.264014  \n",
      "75%                   0.389292  \n",
      "max                   0.950690  \n",
      "\n",
      "[11 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Summary Statistics =====\")\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Missing Values per Column =====\n",
      "Timestamp                 0\n",
      "Age                       0\n",
      "BMI                       0\n",
      "Comorbidity               0\n",
      "Symptom                   0\n",
      "CA125                     0\n",
      "CancerStage               0\n",
      "Histopathology            0\n",
      "PreviousTreatment         0\n",
      "MenstrualHistory          0\n",
      "Ethnicity                 0\n",
      "Smoking                   0\n",
      "Alcohol                   0\n",
      "Residence                 0\n",
      "SocioeconomicStatus       0\n",
      "BRCA_Mutation             0\n",
      "GeneExpression            0\n",
      "SNP_Status                0\n",
      "DNAMethylation            0\n",
      "miRNA                     0\n",
      "TumorSize                 0\n",
      "TumorLocation             0\n",
      "EnhancementPattern        0\n",
      "RadiomicTexture           0\n",
      "RadiomicIntensity         0\n",
      "RadiomicShape             0\n",
      "DopplerVelocity           0\n",
      "Parity                    0\n",
      "OralContraceptives        0\n",
      "HormoneTherapy            0\n",
      "MenarcheAge               0\n",
      "MenopauseAge              0\n",
      "RiskLabel                 0\n",
      "ProgressionProbability    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n===== Missing Values per Column =====\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Duplicate Records\n",
    "Removing duplicate records is essential to prevent bias and redundancy in the analysis.  \n",
    "Maintaining data quality is a critical step in the early detection modeling pipeline, as emphasized in relevant research (Chen et al., 2019) :contentReference[oaicite:2]{index=2}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed. Data shape after duplicate removal: (200100, 34)\n"
     ]
    }
   ],
   "source": [
    "# Remove duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "print(\"Duplicates removed. Data shape after duplicate removal:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Numerical and Categorical Features\n",
    "It is necessary to separate numerical and categorical features because each type requires different preprocessing strategies.  \n",
    "For instance, numerical features might need imputation and scaling, while categorical features require imputation and encoding.  \n",
    "This strategy is commonly adopted in integrative data analysis for ovarian cancer detection (Chen et al., 2019) :contentReference[oaicite:3]{index=3}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['Age', 'BMI', 'Comorbidity', 'Symptom', 'CA125', 'CancerStage', 'PreviousTreatment', 'Smoking', 'Alcohol', 'BRCA_Mutation', 'GeneExpression', 'SNP_Status', 'DNAMethylation', 'miRNA', 'TumorSize', 'EnhancementPattern', 'RadiomicTexture', 'RadiomicIntensity', 'RadiomicShape', 'DopplerVelocity', 'Parity', 'OralContraceptives', 'HormoneTherapy', 'MenarcheAge', 'MenopauseAge', 'RiskLabel', 'ProgressionProbability']\n",
      "Categorical columns: ['Timestamp', 'Histopathology', 'MenstrualHistory', 'Ethnicity', 'Residence', 'SocioeconomicStatus', 'TumorLocation']\n"
     ]
    }
   ],
   "source": [
    "# Identify numerical and categorical columns\n",
    "num_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_cols = df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"Numerical columns:\", num_cols)\n",
    "print(\"Categorical columns:\", cat_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Numerical Features\n",
    "For numerical data, we first impute missing values using the median.  \n",
    "Median imputation is robust to outliers. After imputation, we apply standard scaling to normalize the data.  \n",
    "Scaling improves model convergence and is a standard procedure in clinical data preprocessing (Chen et al., 2019) :contentReference[oaicite:4]{index=4}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical features preprocessed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create an imputer and scaler for numerical features\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "num_scaler = StandardScaler()\n",
    "\n",
    "# Impute missing values in numerical columns\n",
    "df[num_cols] = num_imputer.fit_transform(df[num_cols])\n",
    "# Scale the numerical features\n",
    "df[num_cols] = num_scaler.fit_transform(df[num_cols])\n",
    "\n",
    "print(\"Numerical features preprocessed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Categorical Features\n",
    "For categorical data, missing values are filled using the most frequent value (mode) strategy.  \n",
    "After imputation, we convert categorical variables to a numerical format using one-hot encoding, which is crucial for machine learning models.  \n",
    "These techniques are widely validated in research focused on early detection of ovarian cancer (Chen et al., 2019) :contentReference[oaicite:5]{index=5}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features preprocessed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Impute missing values in categorical columns\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_cat = encoder.fit_transform(df[cat_cols])\n",
    "encoded_cat_df = pd.DataFrame(encoded_cat, columns=encoder.get_feature_names_out(cat_cols))\n",
    "# Exclude timestamp column from encoding\n",
    "timestamp_col = 'Timestamp'\n",
    "cat_cols.remove(timestamp_col)\n",
    "encoded_cat = encoder.fit_transform(df[cat_cols])\n",
    "encoded_cat_df = pd.DataFrame(encoded_cat, columns=encoder.get_feature_names_out(cat_cols))\n",
    "encoded_cat_df[timestamp_col] = df[timestamp_col].values\n",
    "# Drop the original categorical columns and merge the encoded features\n",
    "df = df.drop(columns=cat_cols)\n",
    "df = pd.concat([df.reset_index(drop=True), encoded_cat_df.reset_index(drop=True)], axis=1)\n",
    "\n",
    "print(\"Categorical features preprocessed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original categorical dimensions: 6\n",
      "Encoded categorical dimensions: 16\n",
      "Increased dimensions due to encoding: 11\n"
     ]
    }
   ],
   "source": [
    "original_cat_dims = len(cat_cols)\n",
    "encoded_cat_dims = encoded_cat.shape[1]\n",
    "increased_dims = encoded_cat_dims - original_cat_dims\n",
    "# Remove the last dimension of Timestamp\n",
    "encoded_cat_df = encoded_cat_df.drop(columns=[timestamp_col])\n",
    "encoded_cat_dims -= 1\n",
    "print(\"Original categorical dimensions:\", original_cat_dims)\n",
    "print(\"Encoded categorical dimensions:\", encoded_cat_dims)\n",
    "print(\"Increased dimensions due to encoding:\", increased_dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Cleaned Dataset\n",
    "After preprocessing, we save the cleaned dataset to disk.  \n",
    "A reproducible and well-documented dataset is crucial for subsequent modeling and ensures that research findings can be validated by peers (Chen et al., 2019) :contentReference[oaicite:6]{index=6}.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (200100, 43)\n",
      "Cleaned dataset saved successfully to: Ovarian_patient_data_clean.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset\n",
    "output_path = 'Ovarian_patient_data_clean.csv'\n",
    "df = df.iloc[:, :-1]\n",
    "print(f\"Shape: {df.shape}\")\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Cleaned dataset saved successfully to:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
